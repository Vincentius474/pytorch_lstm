{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0lE5C3lj1LuneTgH5vyXI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vincentius474/pytorch_lstm/blob/main/pytorch_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SunQqLXQ9Kin"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "training_data = datasets.FashionMNIST(root=\"../fashion_mnist\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_data = datasets.FashionMNIST(root=\"../fashion_mnist\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "train_data_loader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_data_loader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOf216fv-HOJ",
        "outputId": "dc60b218-a4de-46d3-e39d-3a9776a136f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.6MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 230kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.77MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 17.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- define hyperparameters"
      ],
      "metadata": {
        "id": "pidExIXvD7lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_len = 28\n",
        "input_len = 28\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "Y6LdC3pa_Xx3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- create the model"
      ],
      "metadata": {
        "id": "gSpZKPs5D4by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_len, hidden_size, num_classes, num_layers):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_len, hidden_size, num_layers, batch_first=True)\n",
        "    self.output_layer = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, X):\n",
        "    hidden_states = torch.zeros(self.num_layers, X.size(0), self.hidden_size)\n",
        "    cell_states = torch.zeros(self.num_layers, X.size(0), self.hidden_size)\n",
        "    out, _ = self.lstm(X, (hidden_states, cell_states))\n",
        "    out = self.output_layer(out[:, -1, :])\n",
        "    return out"
      ],
      "metadata": {
        "id": "fk_rvBVu_yHg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- instantiate the model"
      ],
      "metadata": {
        "id": "dybER2ooEKIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= LSTM(input_len, hidden_size, num_classes, num_layers)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvpEqAXACyFw",
        "outputId": "731502db-49f6-483e-d08a-e624da9df2a7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(\n",
            "  (lstm): LSTM(28, 128, num_layers=2, batch_first=True)\n",
            "  (output_layer): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- define loss function (Cross Entropy) and an optimizer (SDG)"
      ],
      "metadata": {
        "id": "lNTZkdMfDiv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "f1pOKM1fDGhD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- define the training function"
      ],
      "metadata": {
        "id": "6lEQPluoGYNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, model, train_data_loader, loss_func):\n",
        "  total_steps = len(train_data_loader)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for batch,  (images, label) in enumerate(train_data_loader):\n",
        "      images = images.reshape(-1, sequence_len, input_len)\n",
        "\n",
        "      output = model(images)\n",
        "      loss = loss_func(output, label)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (batch + 1)%100 == 0:\n",
        "        print(f\"Epoch : {epoch + 1}; Batch: {batch} / {total_steps}; Loss: {loss.item():>4f}\")"
      ],
      "metadata": {
        "id": "3KK0qk1LDg02"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- train the model"
      ],
      "metadata": {
        "id": "dmeuukuuGcX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(num_epochs, model, train_data_loader, loss_func)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1zIqBMJFHYa",
        "outputId": "8c361c96-c0b3-4c44-d424-fb60eff2232c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1; Batch: 99 / 600; Loss: 2.303062\n",
            "Epoch : 1; Batch: 199 / 600; Loss: 2.296859\n",
            "Epoch : 1; Batch: 299 / 600; Loss: 2.294654\n",
            "Epoch : 1; Batch: 399 / 600; Loss: 2.290643\n",
            "Epoch : 1; Batch: 499 / 600; Loss: 2.291373\n",
            "Epoch : 1; Batch: 599 / 600; Loss: 2.287902\n",
            "Epoch : 2; Batch: 99 / 600; Loss: 2.285956\n",
            "Epoch : 2; Batch: 199 / 600; Loss: 2.282296\n",
            "Epoch : 2; Batch: 299 / 600; Loss: 2.270540\n",
            "Epoch : 2; Batch: 399 / 600; Loss: 2.270716\n",
            "Epoch : 2; Batch: 499 / 600; Loss: 2.270984\n",
            "Epoch : 2; Batch: 599 / 600; Loss: 2.257068\n",
            "Epoch : 3; Batch: 99 / 600; Loss: 2.251699\n",
            "Epoch : 3; Batch: 199 / 600; Loss: 2.247506\n",
            "Epoch : 3; Batch: 299 / 600; Loss: 2.214070\n",
            "Epoch : 3; Batch: 399 / 600; Loss: 2.211253\n",
            "Epoch : 3; Batch: 499 / 600; Loss: 2.205462\n",
            "Epoch : 3; Batch: 599 / 600; Loss: 2.167673\n",
            "Epoch : 4; Batch: 99 / 600; Loss: 2.133408\n",
            "Epoch : 4; Batch: 199 / 600; Loss: 2.118080\n",
            "Epoch : 4; Batch: 299 / 600; Loss: 1.996899\n",
            "Epoch : 4; Batch: 399 / 600; Loss: 1.941476\n",
            "Epoch : 4; Batch: 499 / 600; Loss: 1.872456\n",
            "Epoch : 4; Batch: 599 / 600; Loss: 1.749401\n",
            "Epoch : 5; Batch: 99 / 600; Loss: 1.680078\n",
            "Epoch : 5; Batch: 199 / 600; Loss: 1.765658\n",
            "Epoch : 5; Batch: 299 / 600; Loss: 1.561654\n",
            "Epoch : 5; Batch: 399 / 600; Loss: 1.567593\n",
            "Epoch : 5; Batch: 499 / 600; Loss: 1.557595\n",
            "Epoch : 5; Batch: 599 / 600; Loss: 1.449405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images, test_labels = next(iter(test_data_loader))\n",
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59xaN6k-N_TN",
        "outputId": "bd9d5818-afae-44e1-b5d1-b0e8dc7752e7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
              "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
              "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1, 2, 3, 9, 8, 7, 0,\n",
              "        2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 6, 5, 3, 6, 7, 1, 8,\n",
              "        0, 1, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_output = model(test_images.view(-1, 28, 28))"
      ],
      "metadata": {
        "id": "O4WsYEMyOjSK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = torch.max(test_output, 1)[1]\n",
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83P3nlh0O1Zv",
        "outputId": "a4c87742-a043-4cf3-eee2-318881f92398"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 2, 1, 1, 4, 1, 9, 2, 7, 7, 9, 7, 7, 1, 4, 1, 9, 2, 9, 0, 2, 7, 7, 7,\n",
              "        1, 9, 4, 0, 9, 0, 2, 0, 1, 0, 4, 3, 7, 7, 7, 9, 0, 1, 0, 7, 4, 7, 4, 1,\n",
              "        2, 4, 2, 9, 7, 2, 4, 2, 9, 2, 9, 1, 7, 7, 2, 7, 1, 1, 3, 3, 7, 2, 7, 7,\n",
              "        2, 0, 4, 1, 1, 4, 9, 2, 1, 2, 7, 9, 7, 0, 3, 4, 0, 2, 7, 1, 4, 7, 1, 9,\n",
              "        3, 1, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = [1 for i in range(100) if predicted[i] == test_labels[i]]\n",
        "percentage_correct = sum(correct)/100\n",
        "print(percentage_correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKnYT3CSPPIo",
        "outputId": "ce807b54-91a6-4fee-c655-2d6c533f29da"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(data_loader, model, loss_func, optimizer):\n",
        "  size = len(data_loader.dataset)\n",
        "  num_batches = len(data_loader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in data_loader:\n",
        "      X = X.reshape(-1, 28, 28)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_func(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error:\\n Accuracy: {(100*correct):>0.1f}%, Avg Loss: {test_loss:>8f}\\n\")\n",
        "  return 100*correct"
      ],
      "metadata": {
        "id": "RAc0pyz6RxkF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(test_data_loader, model, loss_func, optim.Adam(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6grrFRXWSLe",
        "outputId": "364b9f72-2cad-4329-ced0-bab035b4f12d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error:\n",
            " Accuracy: 43.9%, Avg Loss: 1.499860\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.89"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yY2-0h3oWqvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}